{
 "metadata": {
  "name": "",
  "signature": "sha256:699d00246018185da2902fd831904260adcfb7e131f51807bc53ac5a7b8b3c43"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Testing alternative to NNLS: use of gaussian approximation to non-central chi squared"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "0) Run this before any other section"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "import scipy.stats as spst\n",
      "import scipy.special as sps\n",
      "import numpy.random as npr\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy.random as npr\n",
      "import scipy.optimize as spo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def scalarize(x):\n",
      "    x = np.atleast_1d(x)\n",
      "    if len(x)==1:\n",
      "        return x[0]\n",
      "    else:\n",
      "        return x\n",
      "    \n",
      "def column(x):\n",
      "    return np.reshape(x,(-1,1))\n",
      "\n",
      "def numderiv(f,x,delta):\n",
      "    return (f(x+delta)-f(x))/delta\n",
      "\n",
      "def ncx2gauss(x,df):\n",
      "    def ff(nc):\n",
      "        val= .5*np.log(2*np.pi*(2*df+4*nc)) + (nc+df-x)**2/(4*df+8*nc)\n",
      "        ncx2der= 1/(df + 2*nc) + 2*(nc + df-x)/(4*df + 8*nc) - 8*((nc+df-x)/(4*df+8*nc))**2\n",
      "        return val, ncx2der\n",
      "    return ff\n",
      "\n",
      "def ncxloss_gauss(x,df): # gaussian approximation to -ncx log likelihood\n",
      "    def ff(mu):\n",
      "        nc = mu**2\n",
      "        val= .5*np.log(2*np.pi*(2*df+4*nc)) + (nc+df-x)**2/(4*df+8*nc)\n",
      "        ncx2der= 1/(df + 2*nc) + 2*(nc + df-x)/(4*df + 8*nc) - 8*((nc+df-x)/(4*df+8*nc))**2\n",
      "        der = 2*mu*ncx2der\n",
      "        return val,der\n",
      "    return ff\n",
      "\n",
      "def ncxloss_mean(x,df): # gaussian approximation to -ncx log likelihood without variance term\n",
      "    def ff(mu):\n",
      "        nc = mu**2\n",
      "        val= .5*(nc+df-x)**2\n",
      "        ncx2der= nc+df-x\n",
      "        der = 2*mu*ncx2der\n",
      "        return val,der\n",
      "    return ff\n",
      "\n",
      "def ncx2true(x,df):\n",
      "    val0 = -spst.chi2.logpdf(x,df)\n",
      "    def ff(nc):\n",
      "        def calcval(ncc):\n",
      "            val = np.zeros(len(ncc))\n",
      "            val[ncc !=0] = -spst.ncx2.logpdf(x,df,ncc[ncc!=0])\n",
      "            val[ncc ==0] = val0\n",
      "            return val\n",
      "        val = calcval(np.atleast_1d(nc))\n",
      "        dval = calcval(np.atleast_1d(nc + 1e-3))\n",
      "        ncx2der = 1e3*(dval-val)\n",
      "        return scalarize(val), scalarize(ncx2der)\n",
      "    return ff\n",
      "\n",
      "def ncxloss_true(x,df): # true ncx loss calculated using spst\n",
      "    val0 = -spst.chi2.logpdf(x,df)\n",
      "    def ff(mu):\n",
      "        nc = mu**2\n",
      "        def calcval(ncc):\n",
      "            val = np.zeros(len(ncc))\n",
      "            val[ncc !=0] = -spst.ncx2.logpdf(x,df,ncc[ncc!=0])\n",
      "            val[ncc ==0] = val0\n",
      "            return val\n",
      "        val = calcval(np.atleast_1d(nc))\n",
      "        dval = calcval(np.atleast_1d(nc + 1e-3))\n",
      "        ncx2der = 1e3*(dval-val)\n",
      "        der = 2*mu*ncx2der\n",
      "        return scalarize(val),scalarize(der)\n",
      "    return ff\n",
      "\n",
      "def bfgssolve(amat,ls,x0,lb=0.0,nd = True): # use LBFS-G to solve, lb = lower bound, nd = numerical derivative\n",
      "    if nd:\n",
      "        def f(x0):\n",
      "            yh = np.dot(amat,x0)\n",
      "            return sum(np.array([ls[i](yh[i]) for i in range(len(yh))]))\n",
      "        def fprime(x0):\n",
      "            yh = np.dot(amat,x0)\n",
      "            rawg= np.array([numderiv(ls[i],yh[i],1e-3) for i in range(len(yh))])\n",
      "            return np.dot(rawg.T,amat)\n",
      "    else:\n",
      "        def f(x0):\n",
      "            yh = np.dot(amat,x0)\n",
      "            return sum(np.array([ls[i](yh[i])[0] for i in range(len(yh))]))\n",
      "        def fprime(x0):\n",
      "            yh = np.dot(amat,x0)\n",
      "            rawg= np.array([ls[i](yh[i])[1] for i in range(len(yh))])\n",
      "            return np.dot(rawg.T,amat)\n",
      "    bounds = [(lb,100.0)] * len(x0)\n",
      "    res = spo.fmin_l_bfgs_b(f,np.squeeze(x0),fprime=fprime,bounds=bounds)\n",
      "    return res"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1) Basic examples"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Visual comparison of gaussian loss and true loss function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = 100.0\n",
      "df = 10\n",
      "ub = 4*x\n",
      "ncs = np.arange(ub/100,ub,ub/100)\n",
      "ll_true = ncx2true(x,df)\n",
      "ll_gauss = ncx2gauss(x,df)\n",
      "plt.scatter(ncs,ll_true(ncs)[0])\n",
      "plt.scatter(ncs,ll_gauss(ncs)[0],color=\"green\")\n",
      "plt.scatter(ncs[np.isnan(ll_true(ncs)[0])],0.0*ncs[np.isnan(ll_true(ncs)[0])],color=\"red\")\n",
      "plt.show()\n",
      "(max(ll_true(ncs)[0]),min(ll_true(ncs)[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "(56.053404410035199, 3.8929547094843855)"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Comparison of NNLS and gaussian approximation on sparse recovery (random vectors)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = 10000\n",
      "p = 1000\n",
      "amat = np.absolute(npr.normal(0,1,(n,p)))\n",
      "bt0 = np.zeros(p)\n",
      "bt0[:4] = 5\n",
      "df = 10\n",
      "mu = np.dot(amat,bt0)\n",
      "ysq = spst.ncx2.rvs(df,mu**2)\n",
      "ls_gauss = [ncxloss_gauss(y,df) for y in ysq]\n",
      "ls_mean = [ncxloss_mean(y,df) for y in ysq]\n",
      "ls_true = [ncxloss_true(y,df) for y in ysq]\n",
      "def recovery_score(x0): # higher score is better\n",
      "    diff = x0-bt0\n",
      "    return (-sum(diff[diff > 0]), sum(diff[diff <0]))\n",
      "bt = np.squeeze(spo.nnls(amat,np.squeeze(np.sqrt(ysq)))[0])\n",
      "res_gauss = bfgssolve(amat,ls_gauss,np.array(bt),0.0,False)\n",
      "res_mean = bfgssolve(amat,ls_mean,np.array(bt),0.0,False)\n",
      "#res_true = bfgssolve(amat,ls_true,np.array(bt),0.0,False)\n",
      "#[recovery_score(bt),recovery_score(res_gauss[0]),recovery_score(res_true[0])]\n",
      "[recovery_score(bt),recovery_score(res_gauss[0]),recovery_score(res_mean[0])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "[(-0.91227300991181082, -0.48514542007171357),\n",
        " (-0.1338259227374903, -0.11260504714007435),\n",
        " (-0.23376039853958405, -0.15947981901076247)]"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# initialization effect?\n",
      "res_gauss = bfgssolve(amat,ls_gauss,np.array(bt0),0.0,False)\n",
      "res_mean = bfgssolve(amat,ls_mean,np.array(bt0),0.0,False)\n",
      "#res_true = bfgssolve(amat,ls_true,np.array(bt),0.0,False)\n",
      "#[recovery_score(bt),recovery_score(res_gauss[0]),recovery_score(res_true[0])]\n",
      "[recovery_score(bt),recovery_score(res_gauss[0]),recovery_score(res_mean[0])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "[(-1.2733907302607161, -0.74638956236892984),\n",
        " (-0.52208899451310531, -0.39691630963561231),\n",
        " (-0.80155205333020674, -0.52078907593583157)]"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2) Testing on diffusion model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib as mpl\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "os.chdir(\"..\")\n",
      "import donuts.deconv.utils as du"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Generate the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# setting up measurement vectors and fitting vectors\n",
      "kappa = 1.5\n",
      "bvecs = np.sqrt(kappa) * du.geosphere(5)\n",
      "n = np.shape(bvecs)[0]\n",
      "print(\"Number of measurement directions is \"+str(n))\n",
      "sgrid = du.geosphere(8)\n",
      "sgrid = sgrid[sgrid[:,2] >= 0,:]\n",
      "pp = np.shape(sgrid)[0]\n",
      "print(\"Number of candidate directions is \"+str(pp))\n",
      "# do you want plots?\n",
      "plotsignal = False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of measurement directions is 252\n",
        "Number of candidate directions is 341\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# randomly generate parameters\n",
      "true_k = 2\n",
      "true_vs = du.normalize_rows(npr.normal(0,1,(true_k,3)))\n",
      "true_vs[:,2] = np.absolute(true_vs[:,2])\n",
      "true_ws = 0.5*np.ones((true_k,1))/true_k\n",
      "true_sigma = 0.1\n",
      "df = 10\n",
      "y0,y1 = du.simulate_signal_kappa(true_vs,true_ws,bvecs,true_sigma,df)\n",
      "# plot the noiseless signal\n",
      "if plotsignal:\n",
      "    zz = np.squeeze(y1)\n",
      "    fig = plt.figure()\n",
      "    ax = fig.gca(projection='3d')\n",
      "    ax.scatter(zz*bvecs[:,0],zz*bvecs[:,1],zz*bvecs[:,2])\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fit the signal, knwoing the true kappa and sigma"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "amat = du.ste_tan_kappa(sgrid,bvecs)\n",
      "df = 10\n",
      "ysq = (np.squeeze(y1)/true_sigma)**2\n",
      "#ysq = spst.ncx2.rvs(df,mu**2)\n",
      "ls_gauss = [ncxloss_gauss(y,df) for y in ysq]\n",
      "ls_mean = [ncxloss_mean(y,df) for y in ysq]\n",
      "ls_true = [ncxloss_true(y,df) for y in ysq]\n",
      "bt = np.squeeze(spo.nnls(amat,np.squeeze(np.sqrt(ysq)))[0])\n",
      "res_mean = bfgssolve(amat,ls_mean,np.array(bt/true_sigma),0.0,False)\n",
      "bt_mean = res_mean[0]*true_sigma\n",
      "#res_gauss = bfgssolve(amat,ls_gauss,np.array(bt/true_sigma),0.0,False)\n",
      "#bt_gauss = res_gauss[0]*true_sigma\n",
      "#res_true = bfgssolve(amat,ls_true,np.array(bt/true_sigma),0.0,False)\n",
      "#bt_true = res_true[0]*true_sigma\n",
      "\n",
      "\n",
      "def loss_emd(x0):\n",
      "    return du.arc_emd(true_vs,true_ws,sgrid,column(x0))\n",
      "loss_emd(bt),loss_emd(bt_mean)#,loss_emd(bt_mean)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}