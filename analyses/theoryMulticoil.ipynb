{
 "metadata": {
  "name": "",
  "signature": "sha256:0972a8490ac55124bf99c51e456158dbaf6cac4c89f60f4f474c78dacca29c9e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Single-voxel noise estimation with multiple coils and directions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('../spark/sparkDonuts.py', 'r')\n",
      "exec(f.read())\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Model\n",
      " * Consider a single voxel, with measurements in directions $d = 1, ... ,n_d$ and coils $c = 1, ... , n_c$.\n",
      " * The B=0 case is treated as a direction (the 'zero' direction)\n",
      " * The coils have correlated noise, $\\epsilon_dc$\n",
      " * The noise vector for a given direction $\\epsilon_d$ has covariance $\\Omega$, and $\\epsilon_d$ are independent for $d = 1,..., n_d$\n",
      " * Each coil also has a specific sensitivity $s_c \\in [0,1]$\n",
      " * Each direction has an 'ideal signal' $\\mu_d$\n",
      " * Define the separate coil measurements as $$y_{dc} = (s_c\\mu_d + \\epsilon_{dc})^2$$\n",
      " * Define the combined-coil measurement as $$Y_d = \\sum_{c} y_{dc}$$\n",
      " * There might be replicate measurements for a given direction.  \n",
      "    For example, if $d=1$ is the B0 direction, and if 10 B0 measurements were taken, we would write them as \n",
      "    $$Y_1^{(1)}, Y_1^{(2)}, ..., Y_1^{(10)}$$\n",
      "Reference: Aviv et al (2014), Wright and Wald (1997)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Problem\n",
      "\n",
      "We wish to estimate $\\sigma^2_d = Var(Y_d)$ for a given direction.\n",
      "\n",
      "## Option 1: Combined-coil\n",
      "\n",
      "The first option is to make use of multiple **combined-coil** estimates for the same direction.\n",
      "That is,\n",
      "$$\\hat{Var}(Y_d) = \\frac{1}{m-1} \\sum_{i=1}^m (Y_d^{(m)} - \\bar{Y}_d)^2$$\n",
      "This is clearly an unbiased estimated.\n",
      "\n",
      "## Option 2: Multiple-coil\n",
      "\n",
      "The second option is to estimate the covariances of the *separate coils*, and then make use of the fact that since\n",
      "\n",
      "$$Y_d = \\sum_c y_{dc}$$\n",
      "\n",
      "that\n",
      "\n",
      "$$Var(Y_d) = \\sum_{c, c'} Cov(y_{dc}, y_{dc'})$$\n",
      "\n",
      "But how can we estimate the covariance matrix  $\\Sigma_d = (Cov(y_{dc}, y_{dc'}))_{cc'}$?\n",
      "\n",
      "We can do so by combining information from **multiple directions** and **multiple coils**."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Estimating the covariance for multiple coils\n",
      "\n",
      "Let us write the coil measurements in a $n_d \\times n_c$ matrix $M$\n",
      "$$\n",
      "M = \\begin{bmatrix}\n",
      "y_{11} & ...& y_{1 c} & ... & y_{1 n_c} \\\\\n",
      "...& ... & ... & ...& ... \\\\\n",
      "y_{d1} & ...& y_{dc} & ... & y_{d n_c} \\\\\n",
      "... & ... & ...& ... & ... \\\\\n",
      "y_{n_d 1} & ...& y_{n_d c} & ... & y_{n_d n_c}\\end{bmatrix}\n",
      "$$\n",
      "\n",
      "The first step is to estimate $E(y_{dc})$ .\n",
      "To do so, note that $$E[y_{dc}] = s_c^2 \\mu_d^2 + \\sigma^2_d$$\n",
      "where $\\sigma^2_d = Var(\\epsilon_{dc})$ (assumed constant for a given direction).\n",
      "\n",
      "Therefore\n",
      "$$\n",
      "E(M) = \n",
      "\\begin{bmatrix}\n",
      "\\mu_1^2 s_1^2 + \\sigma^2_1 & ...& \\mu_1^2 s_c^2 + \\sigma^2_1 & ... & \\mu_1^2 s_{n_c}^2  + \\sigma^2_1\\\\\n",
      "...& ... & ... & ...& ... \\\\\n",
      "\\mu_d^2 s_1^2  + \\sigma^2_d & ...& \\mu_d^2 s_c^2 +\\sigma^2_d & ... & \\mu_d^2 s_{n_c}^2 +\\sigma^2_d\\\\\n",
      "... & ... & ...& ... & ... \\\\\n",
      "\\mu_{n_d}^2 s_1^2 +\\sigma^2_{n_d} & ...& \\mu_{n_d}^2 s_c^2+\\sigma^2_{n_d} & ... & \\mu_{n_d}^2 s_{n_c}^2+\\sigma^2_{n_d}\n",
      "\\end{bmatrix}\n",
      "$$\n",
      "**which is a rank two matrix.**\n",
      "\n",
      "That is, \n",
      "$$\n",
      "E(M) = \n",
      "\\begin{bmatrix}\\sigma^2_1 \\\\ ... \\\\ \\sigma^2_d \\end{bmatrix} \\begin{bmatrix}1 & ... & 1\\end{bmatrix} + \n",
      "\\begin{bmatrix}\\mu_1^2 \\\\ ... \\\\ \\mu_{n_d}^2\\end{bmatrix} \\begin{bmatrix}s_1^2 & ... & s_{n_c}^2\\end{bmatrix}\n",
      "$$\n",
      "\n",
      "### Therefore, estimate E(M) by the rank-two approximation of M.\n",
      "\n",
      "Let $\\hat{M}$ denote this rank-two estimate, with entries $m_{dc}$\n",
      "\n",
      "Then estimate $\\hat{Cov}(y_{dc}, y_{dc'}) = (y_{dc} - m_{dc})(y_{dc'} - m_{dc'})$.\n",
      "\n",
      "**Note:** This is not an unbiased estimate, but we can work out a correction factor."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Simulation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.set_printoptions(precision = 1, linewidth = 120)\n",
      "\n",
      "# problem parameters\n",
      "n_c = 32                             # number of coils\n",
      "n_d = 100                            # number of directions\n",
      "mu_d = np.abs(npr.normal(2, 2, n_d)) # ideal signals\n",
      "s_c = np.abs(npr.normal(2, 1, n_c))  # sensitivities\n",
      "s_c = s_c/max(s_c)                   # so s in [0,1]\n",
      "sigma_d = 0.3 * np.ones(n_d)         # noise standard deviations: use the same for all directions\n",
      "coil_independence = 1000             # controls degree of independence (larger = more independent)\n",
      "\n",
      "# generate the covariance matrix for noise\n",
      "temp = npr.randn(n_c, coil_independence)\n",
      "omega = np.corrcoef(temp)\n",
      "L_omega = np.linalg.cholesky(omega)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 284
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Compute ground truth for direction 1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nreps_est = 100000\n",
      "reps = np.zeros(nreps_est)\n",
      "d = 0\n",
      "for rep_no in range(nreps_est):\n",
      "    temp = np.zeros(n_c)\n",
      "    # generate noise\n",
      "    eps = np.squeeze(np.dot(L_omega, npr.randn(n_c)))\n",
      "    for c in range(n_c):\n",
      "        temp[c] = (s_c[c]*mu_d[d] + sigma_d[d] * eps[c])**2\n",
      "    reps[rep_no] = sum(temp)\n",
      "\n",
      "var_gt = 1.0/(nreps_est-1) * sum((reps - np.mean(reps))**2)\n",
      "print(\"Ground truth variance: \" + str(var_gt))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Ground truth variance: 56.1419906373\n"
       ]
      }
     ],
     "prompt_number": 285
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Generate data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nreps = 2  # number of replicate datasets\n",
      "# generate the individual coil signals\n",
      "y_dc = [None] * nreps\n",
      "for rep_no in range(nreps):\n",
      "    y_dc[rep_no] = np.zeros((n_d, n_c))\n",
      "    for d in range(n_d):\n",
      "        # generate noise\n",
      "        eps = np.squeeze(np.dot(L_omega, npr.randn(n_c)))\n",
      "        for c in range(n_c):\n",
      "            y_dc[rep_no][d, c] = (s_c[c]*mu_d[d] + sigma_d[d] * eps[c])**2\n",
      "\n",
      "# generate the single-coil signals\n",
      "Y_d = [None] * nreps\n",
      "for rep_no in range(nreps):\n",
      "    Y_d[rep_no] = np.zeros(n_d)\n",
      "    for d in range(n_d):\n",
      "        Y_d[rep_no][d] = sum(y_dc[rep_no][d, :])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 286
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Comparison\n",
      "\n",
      "* **Option 1: Replicate measurements:** Use 10 replicate measurements\n",
      "* **Option 2: Rank 2 trick:** Only use one replicate, but use separate coils and all directions\n",
      "   1. Assume coil independence\n",
      "   2. No assumption"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Option 1\n",
      "\n",
      "nreps_o1 = nreps\n",
      "reps = np.array([Y_d[rep_no][0] for rep_no in range(nreps_o1)])\n",
      "var_hat_1 = 1.0/(nreps_o1-1) * sum((reps - np.mean(reps))**2)\n",
      "\n",
      "# Option 2\n",
      "\n",
      "M = y_dc[0]\n",
      "yd0 = y_dc[0][0, :]\n",
      "# compute M_hat\n",
      "u, s, v = nla.svd(M, full_matrices = False)\n",
      "Mhat = np.dot(np.dot(u[:, 0:1], np.diag(s[0:1])), v[0:1,:])\n",
      "Mhat_d0 = Mhat[0, :]\n",
      "# compute cov_hat\n",
      "cov_hat = np.zeros((n_c, n_c))\n",
      "for c1 in range(n_c):\n",
      "    for c2 in range(n_c):\n",
      "        cov_hat[c1, c2] = (yd0[c1] - Mhat_d0[c1])*(yd0[c2] - Mhat_d0[c2])\n",
      "# estimate variance Y_0\n",
      "var_hat_2ind = sum((yd0 - Mhat[0, :])**2) # use independence assumption\n",
      "var_hat_2 = sum(cov_hat.ravel()) # no assumption\n",
      "vals = np.array([var_hat_1, var_hat_2ind, var_hat_2])\n",
      "errs = (vals - var_gt)**2\n",
      "\n",
      "print(\"Ground truth variance\\t\\t: \" + str(\"%.5f\" % var_gt)+\"\\n\")\n",
      "\n",
      "titles = [\"Option 1 (\" + str(nreps_o1) + \" replicates)\\t\\t: \", \"Opt. 2 - Independence\\t\\t: \", \"Opt. 2 - No assumption\\t\\t: \"]\n",
      "obs = [nreps_o1, 1, 1]\n",
      "for ii in range(3):\n",
      "    print(titles[ii] + str(\"%.5f\" % vals[ii]))\n",
      "    print \"Squared error           \\t:\",\n",
      "    print str(\"%.5f\" % errs[ii]),\n",
      "    if (errs[ii] == min(errs)):\n",
      "        print \" (BEST)\\n\"\n",
      "    else:\n",
      "        print(\"\\n\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Ground truth variance\t\t: 56.14199\n",
        "\n",
        "Option 1 (2 replicates)\t\t: 21.96150\n",
        "Squared error           \t: 1168.30599 \n",
        "\n",
        "Opt. 2 - Independence\t\t: 77.94411\n",
        "Squared error           \t: 475.33239 \n",
        "\n",
        "Opt. 2 - No assumption\t\t: 42.94079\n",
        "Squared error           \t: 174.27160  (BEST)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 287
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Many runs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Number of runs\n",
      "nruns = 10\n",
      "record_vals = np.zeros((nruns, 3))\n",
      "record_errs = np.zeros((nruns, 3))\n",
      "# Use parameters from before\n",
      "mu_d = np.abs(npr.normal(2, 2, n_d)) # ideal signals\n",
      "s_c = np.abs(npr.normal(2, 1, n_c))  # sensitivities\n",
      "s_c = s_c/max(s_c)                   # so s in [0,1]\n",
      "sigma_d = 0.3 * np.ones(n_d)         # noise standard deviations: use the same for all directions\n",
      "coil_independence = 1000             # controls degree of independence (larger = more independent)\n",
      "temp = npr.randn(n_c, coil_independence)\n",
      "omega = np.corrcoef(temp)\n",
      "L_omega = np.linalg.cholesky(omega)\n",
      "reps = np.zeros(nreps_est)\n",
      "# ground truth\n",
      "reps = np.zeros(nreps_est)\n",
      "d = 0\n",
      "for rep_no in range(nreps_est):\n",
      "    temp = np.zeros(n_c)\n",
      "    # generate noise\n",
      "    eps = np.squeeze(np.dot(L_omega, npr.randn(n_c)))\n",
      "    for c in range(n_c):\n",
      "        temp[c] = (s_c[c]*mu_d[d] + sigma_d[d] * eps[c])**2\n",
      "    reps[rep_no] = sum(temp)\n",
      "var_gt = 1.0/(nreps_est-1) * sum((reps - np.mean(reps))**2)\n",
      "\n",
      "for rep_no in range(nreps_est):\n",
      "    temp = np.zeros(n_c)\n",
      "    # generate noise\n",
      "    eps = np.squeeze(np.dot(L_omega, npr.randn(n_c)))\n",
      "    for c in range(n_c):\n",
      "        temp[c] = (s_c[c]*mu_d[d] + sigma_d[d] * eps[c])**2\n",
      "    reps[rep_no] = sum(temp)\n",
      "for run_no in range(nruns):\n",
      "    # generate the individual coil signals\n",
      "    y_dc = [None] * nreps\n",
      "    for rep_no in range(nreps):\n",
      "        y_dc[rep_no] = np.zeros((n_d, n_c))\n",
      "        for d in range(n_d):\n",
      "            # generate noise\n",
      "            eps = np.squeeze(np.dot(L_omega, npr.randn(n_c)))\n",
      "            for c in range(n_c):\n",
      "                y_dc[rep_no][d, c] = (s_c[c]*mu_d[d] + sigma_d[d] * eps[c])**2\n",
      "    # generate the single-coil signals\n",
      "    Y_d = [None] * nreps\n",
      "    for rep_no in range(nreps):\n",
      "        Y_d[rep_no] = np.zeros(n_d)\n",
      "        for d in range(n_d):\n",
      "            Y_d[rep_no][d] = sum(y_dc[rep_no][d, :])\n",
      "    # Option 1\n",
      "    reps = np.array([Y_d[rep_no][0] for rep_no in range(nreps_o1)])\n",
      "    var_hat_1 = 1.0/(nreps_o1-1) * sum((reps - np.mean(reps))**2)\n",
      "    # Option 2\n",
      "    M = y_dc[0]\n",
      "    yd0 = y_dc[0][0, :]\n",
      "    # compute M_hat\n",
      "    u, s, v = nla.svd(M, full_matrices = False)\n",
      "    Mhat = np.dot(np.dot(u[:, 0:1], np.diag(s[0:1])), v[0:1,:])\n",
      "    Mhat_d0 = Mhat[0, :]\n",
      "    # compute cov_hat\n",
      "    cov_hat = np.zeros((n_c, n_c))\n",
      "    for c1 in range(n_c):\n",
      "        for c2 in range(n_c):\n",
      "            cov_hat[c1, c2] = (yd0[c1] - Mhat_d0[c1])*(yd0[c2] - Mhat_d0[c2])\n",
      "    # estimate variance Y_0\n",
      "    var_hat_2ind = sum((yd0 - Mhat[0, :])**2) # use independence assumption\n",
      "    var_hat_2 = sum(cov_hat.ravel()) # no assumption\n",
      "    vals = np.array([var_hat_1, var_hat_2ind, var_hat_2])\n",
      "    errs = (vals - var_gt)**2\n",
      "    record_vals[run_no, :] = vals\n",
      "    record_errs[run_no, :] = errs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 293
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean_vals = np.mean(record_vals, axis = 0)\n",
      "mean_errs = np.mean(record_errs, axis = 0)\n",
      "\n",
      "print(\"Ground truth variance\\t\\t: \" + str(\"%.5f\" % var_gt)+\"\\n\")\n",
      "\n",
      "for ii in range(3):\n",
      "    print(titles[ii] + str(\"%.5f\" % mean_vals[ii]) + \" mean\")\n",
      "    print \"Squared error           \\t:\",\n",
      "    print str(\"%.5f\" % mean_errs[ii]),\n",
      "    if (errs[ii] == min(errs)):\n",
      "        print \" (BEST)\\n\"\n",
      "    else:\n",
      "        print(\"\\n\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Ground truth variance\t\t: 2.80041\n",
        "\n",
        "Option 1 (2 replicates)\t\t: 1.75653 mean\n",
        "Squared error           \t: 5.03842 \n",
        "\n",
        "Opt. 2 - Independence\t\t: 2.93054 mean\n",
        "Squared error           \t: 1.55281  (BEST)\n",
        "\n",
        "Opt. 2 - No assumption\t\t: 2.52144 mean\n",
        "Squared error           \t: 2.09259 \n",
        "\n"
       ]
      }
     ],
     "prompt_number": 294
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Further work\n",
      "\n",
      "Assuming correlation structure is shared, pool correlation estimates across directions and voxels"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}